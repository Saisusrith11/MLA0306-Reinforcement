{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the grid world (states)\n",
        "states = [(0, 0), (0, 1), (0, 2),\n",
        "          (1, 0), (1, 1), (1, 2),\n",
        "          (2, 0), (2, 1), (2, 2)]\n",
        "\n",
        "# Define possible actions (up, down, left, right)\n",
        "actions = {'U': (-1, 0), 'D': (1, 0), 'L': (0, -1), 'R': (0, 1)}\n",
        "\n",
        "# Define the state transition function\n",
        "def transition(state, action):\n",
        "    if state in states:\n",
        "        new_state = (state[0] + action[0], state[1] + action[1])\n",
        "        if new_state in states:\n",
        "            return new_state\n",
        "    return state  # Stay in the same state if the action leads to an invalid state\n",
        "\n",
        "# Define the rewards for each state\n",
        "rewards = {\n",
        "    (0, 0): -0.5,\n",
        "    (0, 1): -1,\n",
        "    (0, 2): -0.5,\n",
        "    (1, 0): -1,\n",
        "    (1, 2): -0.5,\n",
        "    (2, 0): -1,\n",
        "    (2, 1): -0.5,\n",
        "    (2, 2): 1,  # The goal state with a reward of 1\n",
        "}\n",
        "\n",
        "# Define the discount factor\n",
        "gamma = 0.9\n",
        "# Define a policy (agent's strategy) - deterministic for simplicity\n",
        "policy = {\n",
        "    (0, 0): 'R',  # Move right when in (0, 0)\n",
        "    (0, 1): 'D',\n",
        "    (0, 2): 'U',\n",
        "    (1, 0): 'R',\n",
        "    (1, 2): 'L',\n",
        "    (2, 0): 'R',\n",
        "    (2, 1): 'U',\n",
        "    (2, 2): 'U',  # Move up when in (2, 2)\n",
        "}\n",
        "\n",
        "# Perform value iteration to find the optimal values of each state\n",
        "V = {state: 0 for state in states}\n",
        "\n",
        "while True:\n",
        "    delta = 0\n",
        "    for state in states:\n",
        "        if state not in policy:\n",
        "            continue\n",
        "        v = V[state]\n",
        "        action = policy[state]\n",
        "        next_state = transition(state, actions[action])\n",
        "        reward = rewards[state]  # Corrected line\n",
        "        V[state] = reward + gamma * V[next_state]\n",
        "        delta = max(delta, abs(v - V[state]))\n",
        "    if delta < 1e-6:\n",
        "        break\n",
        "\n",
        "# Print the values of each state\n",
        "for i in range(3):\n",
        "    for j in range(3):\n",
        "        state = (i, j)\n",
        "        print(f\"State {state}: Value = {V[state]:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiCwLctyfMBu",
        "outputId": "270e669b-7afd-4024-a55d-1a04a510535f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "State (0, 0): Value = -1.40\n",
            "State (0, 1): Value = -1.00\n",
            "State (0, 2): Value = -5.00\n",
            "State (1, 0): Value = -1.00\n",
            "State (1, 1): Value = 0.00\n",
            "State (1, 2): Value = -0.50\n",
            "State (2, 0): Value = -1.45\n",
            "State (2, 1): Value = -0.50\n",
            "State (2, 2): Value = 0.55\n"
          ]
        }
      ]
    }
  ]
}